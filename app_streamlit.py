# app_streamlit.py â€” Streamlit ì›¹ UI

import os, re
from concurrent.futures import ThreadPoolExecutor, as_completed

import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup

import semipro_core as core  # ìœ„ ì½”ì–´ íŒŒì¼

# --- session init ---
if "last_results" not in st.session_state:
    st.session_state.last_results = None

# ---- í˜ì´ì§€ ì„¤ì • ----
st.set_page_config(page_title="SEMPIO Global Safety Research", layout="wide")

# ---- ìƒ˜í‘œ CI í—¤ë” ----
import base64, io

def _img_b64(path: str):
    try:
        with open(path, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception:
        return None

_logo64 = _img_b64("sempio_logo.png")
st.markdown(
    f"""
    <div style="display:flex;align-items:center;margin:12px 0 12px 0;">
      {f'<img src="data:image/png;base64,{_logo64}" style="width:54px;margin-right:14px;">' if _logo64 else ''}
      <div style="line-height:1.25">
        <h1 style="margin:0;font-weight:800;">SEMPIO Global Safety Research</h1>
        <h3 style="margin:4px 0 0 0;color:gray;">Food Additives Database</h3>
        <div style="margin:4px 0 0 0;color:#666;">êµ­ê°€ë³„ ì‹í’ˆì²¨ê°€ë¬¼ ì‚¬ìš©ê¸°ì¤€ ê²€ìƒ‰</div>
      </div>
    </div>
    """,
    unsafe_allow_html=True
)
st.write("---")
# --- ë³¸ë¬¸ ìƒë‹¨ ê²€ìƒ‰ì°½(ìŠ¤í¬ë¦°ìƒ· ìœ„ì¹˜) ---
c1, c2, c3 = st.columns([5, 2, 1])
with c1:
    query = st.text_input("ì›ë£Œëª… ë˜ëŠ” ì˜ë¬¸ëª… ì…ë ¥", placeholder="ì˜ˆ) ê¸€ë¦¬ì‹  / glycine / 56-40-6")
with c2:
    st.write("&nbsp;")
    go = st.button("ê²€ìƒ‰", type="primary")
with c3:
    st.write("&nbsp;")
    clear = st.button("ì§€ìš°ê¸°")
if clear:
    st.session_state.pop("last_results", None)

# ---- Gemini (ì„ íƒ) ----
GEMINI_API_KEY = "ì—¬ê¸°ì—_ë³¸ì¸_Gemini_API_í‚¤"
GEMINI_MODEL = None
try:
    import google.generativeai as genai
    if GEMINI_API_KEY.strip():
        genai.configure(api_key=GEMINI_API_KEY.strip())
        GEMINI_MODEL = genai.GenerativeModel("gemini-2.5-flash")
except Exception as e:
    st.sidebar.warning(f"Gemini ë¡œë“œ ì‹¤íŒ¨: {e}")


# ---- ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë” + ê²€ìƒ‰ ì„¤ì • ----
with st.sidebar:
    st.header("ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ")
    kr_file = st.file_uploader("KR ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx", "xls"], key="kr_file")
    us_file = st.file_uploader("US ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx", "xls"], key="us_file")
    eu_file = st.file_uploader("EU ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx", "xls"], key="eu_file")

    st.divider()
    algo = st.selectbox("ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜", ["token_set_ratio", "ratio", "partial_ratio"], index=0)
    thr  = st.slider("ì„ê³„ê°’", 50, 100, 85)

# ì—…ë¡œë“œ ê°€ë“œ
if not (kr_file and us_file and eu_file):
    st.warning("ì™¼ìª½ì—ì„œ KR/US/EU ì—‘ì…€ì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ë©´ ê²€ìƒ‰ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
    st.stop()

# ---- ê²€ìƒ‰ ìºì‹œ ----
@st.cache_data(show_spinner=False)
def search_records(kind: str, fileobj, query: str, algo_key: str, threshold: float):
    db = core.ChemicalDB(kind, fileobj)
    db.load()
    res = db.search(query, algo_key=algo_key, threshold=float(threshold))
    return db, res

# --- (ì´ ë¶€ë¶„ ìœ„ì—ëŠ” ìºì‹œ í•¨ìˆ˜ ë“± ìˆì„ ìˆ˜ ìˆìŒ) ---

def _expand_terms_korean(first_query: str) -> list:
    """KR DBì—ì„œ ì˜ë¬¸ëª…Â·CASë¥¼ ì°¾ì•„ ê²€ìƒ‰ì–´ í™•ì¥ (Gemini ë¯¸ì‚¬ìš© ë²„ì „)."""
    terms = [first_query]

    # í•œê¸€ í¬í•¨ ì‹œ KR DBì—ì„œ ì˜ë¬¸ëª…Â·CAS ì¶”ì¶œ
    if re.search(r"[ê°€-í£]", first_query):
        try:
            kr_db = core.ChemicalDB("KR", df_kr)
            kr_db.load()
            extra_terms = kr_db.translate_korean_locally(first_query)
            if extra_terms:
                terms.extend(extra_terms)
        except Exception as e:
            print(f"âš ï¸ KR DB í™•ì¥ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
    out, seen = [], set()
    for t in terms:
        if t and t not in seen:
            out.append(t)
            seen.add(t)
    return out


# --- ê²€ìƒ‰ ì‹¤í–‰ ---
if go:
    q = (query or "").strip()
    if not q:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    expanded_terms = _expand_terms_korean(q)

    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        res_map = _search_all(expanded_terms, algo, float(thr))

    (db_kr, res_kr) = res_map["KR"]
    (db_us, res_us) = res_map["US"]
    (db_eu, res_eu) = res_map["EU"]

    total_found = len(res_kr.exact_rows) + len(res_us.exact_rows) + len(res_eu.exact_rows)
    st.success(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {total_found}ê±´ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")

    st.session_state.last_results = ((db_kr, res_kr), (db_us, res_us), (db_eu, res_eu))


# --- ê²€ìƒ‰ ì‹¤í–‰ ---
if go:
    # 1) íŒŒì¼ í™•ì¸ (í•„ìš”í•˜ë‹¤ë©´)
    if not (kr_file and us_file and eu_file):
        st.warning("KR/US/EU ì—‘ì…€ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        st.session_state.last_results = None
        st.stop()

    # 2) ê²€ìƒ‰ì–´ í™•ì¸
    query_norm = (query or "").strip()
    if not query_norm:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•œ ë’¤ â€˜ê²€ìƒ‰â€™ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        st.session_state.last_results = None
        st.stop()

    # 3) ì‹¤ì œ ê²€ìƒ‰
    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        db_kr, res_kr = search_records("KR", kr_file, query_norm, algo, float(thr))
        db_us, res_us = search_records("US", us_file, query_norm, algo, float(thr))
        db_eu, res_eu = search_records("EU", eu_file, query_norm, algo, float(thr))

    # 4) ì„±ê³µ ì‹œì—ë§Œ ì €ì¥
    st.session_state.last_results = ((db_kr, res_kr), (db_us, res_us), (db_eu, res_eu))

# --- ê²°ê³¼ ë³´ì¥ ìœ í‹¸: last_results êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ì§€ ê²€ì‚¬ ---
def _valid_results(obj) -> bool:
    return (
        isinstance(obj, tuple) and len(obj) == 3 and
        all(isinstance(x, tuple) and len(x) == 2 for x in obj)
    )

# â† ì–¸íŒ¨í‚¹í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ê°€ë“œ
results = st.session_state.get("last_results", None)
if not _valid_results(results):
    st.info("ì™¼ìª½ì—ì„œ KR/US/EU íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ê²€ìƒ‰ì–´ ì…ë ¥ â†’ â€˜ê²€ìƒ‰â€™ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    st.stop()

(db_kr, res_kr), (db_us, res_us), (db_eu, res_eu) = results

tabs = st.tabs(["ëŒ€í•œë¯¼êµ­(KR)", "ë¯¸êµ­(US)", "ìœ ëŸ½(EU)"])

def rows_to_df(db, rows):
    cols = [c for c in db.columns_to_display if c]
    data = []
    for r in rows:
        row = [r.data.get(c, "") for c in cols]
        data.append(row)
    return pd.DataFrame(data, columns=[str(c) for c in cols])

# =========================
# KR íƒ­
# =========================
with tabs[0]:
    st.subheader("ì •í™•íˆ ì¼ì¹˜")
    st.dataframe(rows_to_df(db_kr, res_kr.exact_rows), use_container_width=True)
    st.subheader("ìœ ì‚¬ ê²€ìƒ‰ ê²°ê³¼")
    st.dataframe(rows_to_df(db_kr, [r for _, r in res_kr.similar_rows]), use_container_width=True)

    st.divider()
    st.subheader("ìƒì„¸ë³´ê¸°")
    target = res_kr.exact_rows[0] if res_kr.exact_rows else (res_kr.similar_rows[0][1] if res_kr.similar_rows else None)
    if target:
        row = target.data

        # ì‚¬ìš©ê¸°ì¤€ ì›ë¬¸ ì¶”ì¶œ
        usage_keys = ["ì‚¬ìš©ê¸°ì¤€","ì‚¬ìš© ê¸°ì¤€","ì‚¬ìš©ê¸°ì¤€(êµ­ë‚´ê¸°ì¤€)","ì‚¬ìš©ê¸°ì¤€(êµ­ë‚´ê¸°ì¤€)_ì—…ë°ì´íŠ¸"]
        usage = ""
        for k in usage_keys:
            if k in row:
                usage = str(row.get(k, "") or ""); break

        st.markdown("**ì‚¬ìš©ê¸°ì¤€ â€“ AI í‘œ ìš”ì•½**")
        if GEMINI_MODEL and usage.strip():
            with st.spinner("AIê°€ í‘œ í˜•íƒœë¡œ ì •ë¦¬ ì¤‘..."):
                prompt = (
                    "ë‹¤ìŒ 'ì‚¬ìš©ê¸°ì¤€' í•œêµ­ì–´ ì›ë¬¸ì„ í‘œë¡œ êµ¬ì¡°í™”í•´ì¤˜.\n"
                    "- ì»¬ëŸ¼ì€ ê°€ëŠ¥í•˜ë©´ ë‹¤ìŒ ìˆœì„œë¡œ: ì‹í’ˆìœ í˜•\tí—ˆìš©ê¸°ì¤€(ìˆ˜ì¹˜)\tê·¼ê±°/ì¡°ê±´\të¹„ê³ \n"
                    "- ìˆ˜ì¹˜ëŠ” mg/kg, mg/L, %, ë˜ëŠ” GMP/quantum satis ë“± ëª…í™•í‘œê¸°.\n"
                    "- ë°˜ë“œì‹œ TSV(íƒ­ êµ¬ë¶„)ë§Œ ì¶œë ¥.\n\n"
                    f"{usage[:6000]}"
                )
                tsv = GEMINI_MODEL.generate_content(prompt).text.strip()

            lines = [ln for ln in tsv.splitlines() if ln.strip()]
            if len(lines) >= 2:
                headers = [h.strip() for h in lines[0].split("\t")]
                rows = [[c.strip() for c in ln.split("\t")] for ln in lines[1:]]
                df_tsv = pd.DataFrame(rows, columns=headers)
                # ì´ˆê¸° í™”ë©´ì—ì„œë„ í…ìŠ¤íŠ¸ê°€ ì˜ë¦¬ë”ë¼ë„ ëª¨ë“  ì…€ Nì¤„(ì˜ˆ: 4ì¤„)ê¹Œì§€ í‘œì‹œë  ìˆ˜ ìˆë„ë¡ ë†’ì´ í™•ë³´
                st.dataframe(df_tsv, use_container_width=True, height=min(600, 120 + 24*max(4, len(rows))))
            else:
                st.info("TSV íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("API í‚¤ê°€ ì—†ê±°ë‚˜ ì‚¬ìš©ê¸°ì¤€ ì›ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("**AI ì§ˆë¬¸**")
        q_kr = st.text_input("ì§ˆë¬¸ ì…ë ¥", key="kr_q")
        if st.button("ì§ˆë¬¸í•˜ê¸°", key="kr_q_btn") and GEMINI_MODEL and q_kr.strip():
            ctx = "ë‹¤ìŒ í…ìŠ¤íŠ¸ë§Œ ê·¼ê±°ë¡œ ê°„ë‹¨íˆ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”.\n\n" + (usage or "")
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                ans = GEMINI_MODEL.generate_content(f"{ctx}\n\nì§ˆë¬¸: {q_kr.strip()}").text
            st.write(ans)

# =========================
# US íƒ­
# =========================
def _is_cfr(u: str) -> bool:
    u = (u or "").lower()
    return ("ecfr.gov" in u) or ("govinfo.gov" in u) or ("law.cornell.edu/cfr" in u) or ("/cfr/" in u)

def _extract_cfr_text_fast(urls, timeout=5, max_workers=8, stop_after=5):
    headers = {'User-Agent':'Mozilla/5.0'}
    urls = list(dict.fromkeys([u for u in urls if _is_cfr(u)]))
    if not urls:
        return ""

    def fetch_one(u: str):
        try:
            r = requests.get(u, timeout=timeout, headers=headers)
            r.raise_for_status()
            soup = BeautifulSoup(r.content, "html.parser")
            for sel in ["nav","header","footer","script","style","aside"]:
                for el in soup.select(sel):
                    el.decompose()
            text = soup.get_text(" ", strip=True)
            text = re.sub(r"\s+", " ", text)
            keep = []
            for ln in re.split(r"[;\.\n]\s+", text):
                if re.search(r"\b(ppm|mg/kg|mg/L|%|percent|GMP|quantum\s+satis|not\s+more\s+than|"
                             r"shall\s+not\s+exceed|max|limit|residue|used\s+as|for\s+use\s+as)\b", ln, re.I):
                    keep.append(ln.strip())
            text2 = "\n".join(dict.fromkeys(keep)) or text[:3000]
            return f"[SOURCE] {u}\n{text2}", True
        except Exception as e:
            return f"[SOURCE] {u}\n(ìˆ˜ì§‘ ì‹¤íŒ¨: {e})", False

    parts, ok_cnt = [], 0
    with ThreadPoolExecutor(max_workers=min(max_workers, len(urls))) as ex:
        futs = [ex.submit(fetch_one, u) for u in urls]
        for fut in as_completed(futs):
            txt, ok = fut.result()
            parts.append(txt); ok_cnt += int(ok)
            if ok_cnt >= stop_after:
                for f in futs:
                    if not f.done(): f.cancel()
                break
    return "\n\n---\n\n".join(parts)

def gemini_summarize_cfr(combined_source: str) -> str:
    if not GEMINI_MODEL:
        return "(Gemini ë¹„í™œì„±)"
    prompt = (
        "ì•„ë˜ëŠ” CFR(ì—°ë°©ê·œì •) ì„¹ì…˜ë“¤ì—ì„œ ì¶”ì¶œÂ·ì •ë¦¬í•œ ë³¸ë¬¸ ë°œì·Œì…ë‹ˆë‹¤. "
        "íƒìƒ‰/ê²€ìƒ‰ ì•ˆë‚´ë¬¸ ë“± ë¹„ê·œì œì„± ë¬¸êµ¬ëŠ” ë¬´ì‹œí•˜ê³ , ë‹¤ìŒ í•­ëª©ë§Œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.\n"
        "1) ì„¹ì…˜ ë²ˆí˜¸/ì œëª©, 2) ìš©ë„(Used as/For), 3) í—ˆìš© í•œë„(ìˆ˜ì¹˜: %, mg/kg, mg/L, ppm, GMP/quantum satis ë“±), "
        "4) ì œí•œ/ì˜ˆì™¸, 5) ì£¼ì˜Â·ë¹„ê³ . ìˆ˜ì¹˜ê°€ ëª…ì‹œëœ ë¬¸ì¥ë§Œ ìš°ì„ í•©ë‹ˆë‹¤.\n"
        "- ë™ì¼/ìœ ì‚¬ ê·œì •ì€ ë³‘í•©í•˜ê³ , ìƒì¶© ì‹œ ë‘˜ ë‹¤ í‘œê¸°í•˜ë©° ê° í•­ëª© ëì— (ì¶œì²˜: URL) ë¶™ì´ì„¸ìš”.\n"
        "- ê²°ê³¼ëŠ” í‘œ í˜•íƒœ ì—†ì´ ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸ë¡œ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì£¼ì„¸ìš”.\n\n"
        f"{combined_source[:120000]}"
    )
    return GEMINI_MODEL.generate_content(prompt).text

with tabs[1]:
    st.subheader("ì •í™•íˆ ì¼ì¹˜")
    st.dataframe(rows_to_df(db_us, res_us.exact_rows), use_container_width=True)
    st.subheader("ìœ ì‚¬ ê²€ìƒ‰ ê²°ê³¼")
    st.dataframe(rows_to_df(db_us, [r for _, r in res_us.similar_rows]), use_container_width=True)

    st.divider()
    st.subheader("ìƒì„¸ë³´ê¸° + CFR í†µí•© ìš”ì•½")
    tgt = res_us.exact_rows[0] if res_us.exact_rows else (res_us.similar_rows[0][1] if res_us.similar_rows else None)
    if tgt:
        row = tgt.data
        # ëª¨ë“  ì…€ì—ì„œ URL ì¶”ì¶œ í›„ CFRë§Œ
        urls = []
        for v in row.values():
            urls += core.extract_urls(str(v))
        cfr_urls = [u for u in urls if _is_cfr(u)]
        st.write("ì°¾ì€ CFR ë§í¬:", cfr_urls or "(ì—†ìŒ)")

        if st.button(f"ê´€ë ¨ ì›ë¬¸ AI ìš”ì•½ (ìµœëŒ€ {min(len(cfr_urls), 8)}ê°œ)"):
            with st.spinner("ì›ë¬¸ ìˆ˜ì§‘/ìš”ì•½ ì¤‘..."):
                combined = _extract_cfr_text_fast(cfr_urls[:8], timeout=5, max_workers=8, stop_after=5)
                summary = gemini_summarize_cfr(combined) if combined else "(ìˆ˜ì§‘ ì‹¤íŒ¨)"
            st.session_state["last_cfr_combined"] = combined or ""
            st.text_area("ìš”ì•½", summary, height=300)

        # --- ë¯¸êµ­ ìƒì„¸ ì±„íŒ… ---
        st.markdown("### Gemini AI ì±„íŒ… (ë¯¸êµ­ ìƒì„¸)")
        base_ctx = st.session_state.get("last_cfr_combined", "")
        if not base_ctx:
            # ë²„íŠ¼ì„ ì•ˆ ëˆŒë €ì„ ë•ŒëŠ” ìƒì„¸í–‰ ì „ì²´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
            try:
                base_ctx = "\n".join([f"{k}: {v}" for k, v in row.items()])
            except Exception:
                base_ctx = "(ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)"

        with st.expander("í˜„ì¬ ì±„íŒ… ì»¨í…ìŠ¤íŠ¸ ë³´ê¸°", expanded=False):
            st.text_area("ì»¨í…ìŠ¤íŠ¸", base_ctx[:120000], height=240)

        if "us_chat_history" not in st.session_state:
            st.session_state["us_chat_history"] = []

        for turn in st.session_state["us_chat_history"]:
            st.markdown(f"**Q:** {turn['q']}")
            st.markdown(f"**A:** {turn['a']}")
            st.markdown("---")

        with st.form("us_chat_form", clear_on_submit=True):
            q_us = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", "")
            submitted = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°")
            if submitted and q_us.strip():
                if GEMINI_MODEL:
                    prompt = (
                        "ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê·¼ê±°ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µí•´ì£¼ì„¸ìš”.\n\n"
                        f"{base_ctx[:120000]}\n\nì§ˆë¬¸: {q_us.strip()}"
                    )
                    answer = GEMINI_MODEL.generate_content(prompt).text
                else:
                    answer = "(Gemini ë¹„í™œì„±)"
                st.session_state["us_chat_history"].append({"q": q_us.strip(), "a": answer})
                st.experimental_rerun()

# =========================
# EU íƒ­
# =========================
with tabs[2]:
    st.subheader("ì •í™•íˆ ì¼ì¹˜")
    st.dataframe(rows_to_df(db_eu, res_eu.exact_rows), use_container_width=True)
    st.subheader("ìœ ì‚¬ ê²€ìƒ‰ ê²°ê³¼")
    st.dataframe(rows_to_df(db_eu, [r for _, r in res_eu.similar_rows]), use_container_width=True)

    st.info("EU ê·¸ë£¹ í˜ì´ì§€ URLì´ ìˆìœ¼ë©´ ë³„ë„ íŒŒì„œë¡œ í™•ì¥ ê°€ëŠ¥(ì¶”í›„).")
