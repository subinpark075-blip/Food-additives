#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import io
import base64
import pandas as pd
import streamlit as st
import google.generativeai as genai
from threading import Thread

# ---------------------------
# í˜ì´ì§€ & ì „ì—­ ìŠ¤íƒ€ì¼
# ---------------------------
st.set_page_config(page_title="SEMPIO Global Gate - Food Additives", layout="wide")

CUSTOM_CSS = """
<style>
/* ìƒë‹¨ ì—¬ë°±/í°íŠ¸ */
h1, h2, h3 { letter-spacing: .2px; }
.top-wrap { display:flex; align-items:center; margin: 10px 0 20px 0; }
.top-wrap img { width:60px; margin-right:15px; margin-top:-3px; }
.top-wrap h1 { margin:0; font-weight:800; }
.top-wrap h3 { margin:3px 0 0 0; color:gray; font-weight:600; }
/* ì•ˆë‚´ ë°°ì§€ ëŠë‚Œ */
.badge { padding:10px 12px; border-radius:8px; background:#eaf7ef; color:#137333; border:1px solid #cfead6; }
.warn  { padding:10px 12px; border-radius:8px; background:#fff4e5; color:#a15c00; border:1px solid #ffe1b2; }
.note  { font-size:12px; color:#6b7280; margin-top:6px; }
</style>
"""
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# ---------------------------
# ë¡œê³  (Base64 ì¸ì½”ë”©; ì—†ìœ¼ë©´ ìƒëµ)
# ---------------------------
def get_base64_of_image(path: str) -> str | None:
    try:
        with open(path, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception:
        return None

logo_b64 = get_base64_of_image("assets/sempio_logo.png") or get_base64_of_image("sempio_logo.png")

st.markdown(
    f"""
    <div class="top-wrap">
        {'<img src="data:image/png;base64,'+logo_b64+'">' if logo_b64 else ''}
        <div>
            <h1>SEMPIO Global Safety Research</h1>
            <h3>Food Additives Database</h3>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)
st.write("---")

# ---------------------------
# ë°ì´í„° ë¡œë“œ ìœ í‹¸ (ì—…ë¡œë“œ ê¸°ë°˜)
# ---------------------------
@st.cache_data(show_spinner=False)
def read_excel_from_upload(upload) -> pd.DataFrame:
    return pd.read_excel(upload)

def find_column(df: pd.DataFrame, keywords: list[str]) -> str | None:
    for col in df.columns:
        c = str(col).strip().lower()
        for key in keywords:
            if key.lower() in c:
                return col
    return None

# ---------------------------
# ì‚¬ì´ë“œë°”: DB ì—…ë¡œë“œ
# ---------------------------
st.sidebar.header("ë°ì´í„° ì—…ë¡œë“œ")
st.sidebar.caption("ê° DBë³„ ì—‘ì…€ 1ê°œ ì—…ë¡œë“œ ê¶Œì¥ (ë¨¸ì§€ëœ íŒŒì¼ë„ ê°€ëŠ¥)")

kr_up = st.sidebar.file_uploader("KR DB", type=["xlsx", "xls"])
us_up = st.sidebar.file_uploader("US DB", type=["xlsx", "xls"])
eu_up = st.sidebar.file_uploader("EU DB (ì„ íƒ)", type=["xlsx", "xls"])

kr_df = read_excel_from_upload(kr_up) if kr_up else None
us_df = read_excel_from_upload(us_up) if us_up else None
eu_df = read_excel_from_upload(eu_up) if eu_up else None

# ì»¬ëŸ¼ ì •ë¦¬(ê³µí†µ)
for df in (kr_df, us_df, eu_df):
    if df is not None:
        df.columns = df.columns.map(lambda x: str(x).strip())

# ---------------------------
# ê²€ìƒ‰ì°½
# ---------------------------
search = st.text_input("ì›ë£Œëª… ë˜ëŠ” ì˜ë¬¸ëª… ì…ë ¥", placeholder="ì˜ˆ: ê¸€ë¦¬ì‹  / glycine / 56-40-6")

# ---------------------------
# Gemini API ì„¤ì • (ì´ˆê¸°í™”)
# ---------------------------
ENV_KEY = (os.getenv("GOOGLE_API_KEY") or "").strip()
HARDCODED_KEY = "AIzaSyDpPvneo1OyY2a6DUZHgSOWdpcbt9rVx4g"  # API í‚¤ ì„¤ì • (í˜¹ì€ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •)
API_KEY = ENV_KEY if ENV_KEY else HARDCODED_KEY

GEMINI_MODEL = None
CHAT_SESSION = None

if API_KEY:
    try:
        genai.configure(api_key=API_KEY)
        GEMINI_MODEL = genai.GenerativeModel("gemini-2.5-flash")
        CHAT_SESSION = GEMINI_MODEL.start_chat(history=[])
    except Exception as e:
        st.error(f"Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
else:
    st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ GOOGLE_API_KEY ë˜ëŠ” HARDCODED_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

# ---------------------------
# ê²€ìƒ‰ ì‹¤í–‰
# ---------------------------
def filter_df(df: pd.DataFrame, search_txt: str, patterns: list[list[str]]) -> pd.DataFrame:
    """patterns: [[col_keywords...], [col_keywords...], ...]"""
    if df is None or not search_txt:
        return pd.DataFrame()
    # í›„ë³´ ì»¬ëŸ¼ ì°¾ê¸°
    cands = []
    for keys in patterns:
        col = find_column(df, keys)
        if col:
            cands.append(col)
    cands = list(dict.fromkeys(cands))  # ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€

    if not cands:
        return pd.DataFrame()
    mask = False
    for c in cands:
        mask = mask | df[c].astype(str).str.contains(search_txt, case=False, na=False)
    return df.loc[mask].copy()

if search:
    # KR
    kr_res = filter_df(
        kr_df,
        search,
        patterns=[["í•œê¸€ëª…", "ì‹í’ˆì²¨ê°€ë¬¼", "additive"],
                  ["ì˜ë¬¸ëª…", "ì˜ë¬¸", "english", "substance", "name"],
                  ["cas", "cas no", "cas reg"]]
    )
    # US
    us_res = filter_df(
        us_df,
        search,
        patterns=[["í•œê¸€ëª…", "additive"],
                  ["ì˜ë¬¸ëª…", "english", "substance", "name"],
                  ["cas", "cas no", "cas reg"]]
    )
    # EU(ì„ íƒ)
    eu_res = filter_df(
        eu_df,
        search,
        patterns=[["additive_name_en", "name en", "name_en", "additive"],
                  ["cas", "cas list", "cas no", "cas reg"],
                  ["e_number", "e number", "e-number"]]
    )

    # ì´ ê±´ìˆ˜ ë©”ì‹œì§€ (ìŠ¤í¬ë¦°ìƒ· ëŠë‚Œ)
    total_hits = (0 if kr_res is None else len(kr_res)) + (0 if us_res is None else len(us_res)) + (0 if eu_res is None else len(eu_res))
    st.markdown(f"<div class='badge'>ğŸ” ê²€ìƒ‰ ê²°ê³¼: {total_hits}ê±´ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.</div>", unsafe_allow_html=True)

    # íƒ­ êµ¬ì„±: KR / US / EU
    tabs = []
    names = []
    if kr_df is not None:
        tabs.append("KR")
        names.append("ğŸ‡°ğŸ‡· KOREA")
    if us_df is not None:
        tabs.append("US")
        names.append("ğŸ‡ºğŸ‡¸ USA")
    if eu_df is not None:
        tabs.append("EU")
        names.append("ğŸ‡ªğŸ‡º EU")

    if not tabs:
        st.markdown("<div class='warn'>ì—…ë¡œë“œëœ DBê°€ ì—†ìŠµë‹ˆë‹¤. ì¢Œì¸¡ì—ì„œ ìµœì†Œ 1ê°œ ì—…ë¡œë“œí•˜ì„¸ìš”.</div>", unsafe_allow_html=True)
    else:
        t_objs = st.tabs(names)
        ptr = 0

        # ----- KR íƒ­ -----
        if kr_df is not None:
            with t_objs[ptr]:
                st.subheader("ğŸ‡°ğŸ‡· KOREA")
                if not kr_res.empty:
                    st.dataframe(kr_res, use_container_width=True)
                else:
                    st.info("í•œêµ­ DBì—ì„œ ì¼ì¹˜ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            ptr += 1

        # ----- US íƒ­ -----
        if us_df is not None:
            with t_objs[ptr]:
                st.subheader("ğŸ‡ºğŸ‡¸ USA")
                if not us_res.empty:
                    st.dataframe(us_res, use_container_width=True)

                    # CFR ë§í¬ ì—´ ìë™ íƒìƒ‰ í›„ í‘œ ì•„ë˜ ë§í¬ ëª©ë¡ í‘œì‹œ
                    us_cfr = find_column(us_res, ["CFR", "reference", "ë§í¬", "url", "hyperlink"])
                    us_eng = find_column(us_res, ["ì˜ë¬¸ëª…", "ì˜ë¬¸", "english", "substance", "name"])
                    if us_cfr and us_cfr in us_res.columns:
                        st.markdown("---")
                        st.markdown("**CFR Reference Links**")
                        for _, row in us_res.iterrows():
                            name = str(row.get(us_eng, "Unknown"))
                            link = str(row.get(us_cfr, ""))
                            if link.startswith("http"):
                                st.markdown(f"ğŸ”— [{name}]({link})")
                            elif link:
                                st.markdown(f"ğŸ”¹ {name} - {link}")
                        st.markdown("---")
                else:
                    st.info("ë¯¸êµ­ DBì—ì„œ ì¼ì¹˜ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            ptr += 1

        # ----- EU íƒ­ -----
        if eu_df is not None:
            with t_objs[ptr]:
                st.subheader("ğŸ‡ªğŸ‡º EU")
                if not eu_res.empty:
                    st.dataframe(eu_res, use_container_width=True)
                else:
                    st.info("EU DBì—ì„œ ì¼ì¹˜ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

else:
    st.info("ê²€ìƒ‰í•  ì²¨ê°€ë¬¼ëª… ë˜ëŠ” CAS No.ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ---------------------------
# Gemini ìš”ì•½ ê¸°ëŠ¥ ì¶”ê°€ (ì›¹ í˜ì´ì§€ ìš”ì•½)
# ---------------------------
def summarize_url_with_gemini(url: str) -> str:
    if not GEMINI_MODEL:
        return "Gemini APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    try:
        prompt = f"ë‹¤ìŒ ì›¹ í˜ì´ì§€ ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”: {url}"
        summary = GEMINI_MODEL.generate_content(prompt).text
        return summary
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"

# ì›¹í˜ì´ì§€ ìš”ì•½
if search and GEMINI_MODEL:
    summary = summarize_url_with_gemini(f"http://example.com/{search}")
    st.markdown("### ìš”ì•½")
    st.write(summary)

# ---------------------------
# ë””ë²„ê·¸: ì»¬ëŸ¼ í™•ì¸
# ---------------------------
with st.expander("ğŸ” ì—´ ì´ë¦„ í™•ì¸ (í´ë¦­í•˜ì—¬ ë³´ê¸°)"):
    if kr_df is not None:
        st.write("**KR íŒŒì¼ ì»¬ëŸ¼ëª…:**", list(kr_df.columns))
    if us_df is not None:
        st.write("**US íŒŒì¼ ì»¬ëŸ¼ëª…:**", list(us_df.columns))
    if eu_df is not None:
        st.write("**EU íŒŒì¼ ì»¬ëŸ¼ëª…:**", list(eu_df.columns))

st.markdown("<div class='note'>Â© Sempio â€¢ ë‚´ë¶€ ì „ìš© â€¢ </div>", unsafe_allow_html=True)
